import argparse
import os
import sys
import tarfile
import uuid
from os.path import normpath

import requests
from tqdm import tqdm

from util.hasher import calculate_hashes

DATASET_URL = "https://database.clamav.net/main.cvd"
DATASET_FILE = "main.tar"
EXTRACTED_FILE = "main.hdb"
HEADER_SIZE = 512


def download_dataset() -> None:
    """Fetch the ClamAV dataset from the official URL.

    Raises
    ------
        SystemExit: If the dataset fetching fails.
    """
    tqdm.write("Fetching ClamAV dataset...")

    # database.clamav.net requires a special user agent in the request
    # otherwise we get a 403 forbidden error
    user_agent = f"CVDUPDATE/1 ({uuid.uuid4()})"
    headers = {"User-Agent": user_agent}

    response = requests.get(DATASET_URL, headers=headers, stream=True)

    if response.status_code == 200:
        with open(DATASET_FILE, "wb") as f:
            # Skip the proprietary header
            for _ in response.iter_content(HEADER_SIZE):
                break
            # Continue downloading the rest of the file
            for chunk in response.iter_content(chunk_size=1024):
                if chunk:
                    f.write(chunk)

        tqdm.write("Dataset fetched successfully.")
    else:
        tqdm.write(f"Failed to fetch dataset. HTTP Status Code: {response.status_code}")
        sys.exit(1)


def extract_dataset() -> None:
    """Extract the ClamAV dataset from the downloaded tar file.

    Raises
    ------
        SystemExit: If the extraction fails.
    """
    tqdm.write("Extracting ClamAV dataset...")
    with tarfile.open(DATASET_FILE, "r") as tar:
        tar.extract(EXTRACTED_FILE)
        os.chmod(EXTRACTED_FILE, mode=0o655)
    tqdm.write("Dataset extracted successfully.")


def cleanup_files() -> None:
    """Remove files from downloading dataset."""
    tqdm.write(f"Removing: {DATASET_FILE}")
    os.remove(DATASET_FILE)
    tqdm.write("Dataset extracted successfully.")


def load_signatures() -> dict:
    """Load virus signatures from the extracted ClamAV dataset.

    Returns
    -------
        dict: Dictionary containing file hash to file name mappings.
    """
    tqdm.write("Loading signatures")
    with open(EXTRACTED_FILE) as f:
        data = f.readlines()

    sig_dict = {}  # key:file hash, value:file name
    for row in data:
        hash_val, _, virus_name = row.split(":")
        sig_dict[hash_val] = virus_name.strip()

    return sig_dict


def scan_files(search_dirs, sig_dict, max_file_size=None, exclude_dirs=None, verbose=False) -> None:
    """Scan files in specified directories for viruses.

    Args:
    ----
        search_dirs (list): List of directories to scan.
        sig_dict (dict): Dictionary containing virus signatures.
        max_file_size (int): Maximum file size to scan (in MB).
        exclude_dirs (list): Directories to exclude from scanning.
        verbose (bool): If True, log each file scanned.
    """
    tqdm.write(f"Scanning directories {search_dirs}, with max_file_size={max_file_size}")
    files_to_hash = []

    for search_dir in search_dirs:
        search_dir = normpath(search_dir)
        for root, dirs, files in os.walk(search_dir):
            if exclude_dirs:
                exclude_dirs = [normpath(directory) for directory in exclude_dirs]
                dirs = [d for d in dirs if normpath(os.path.join(root, d)) not in exclude_dirs]

            for file in files:
                full_path = os.path.join(root, file)
                files_to_hash.append(full_path)

    matches = []

    for file in tqdm(files_to_hash):
        if verbose:
            tqdm.write(f"Scanning file: {file}.")
        if not os.path.isfile(file):
            continue

        file_size = os.path.getsize(file)
        if max_file_size and file_size > max_file_size:
            tqdm.write(f"Skipping large file {file} with size {file_size}.")
            continue

        md5, sha256 = calculate_hashes(file)

        is_md5_match = md5 in sig_dict
        is_sha256_match = sha256 in sig_dict

        if is_sha256_match or is_md5_match:
            tqdm.write(f"The file is a virus: {file}.")
            matching_hash = sha256 if is_sha256_match else md5
            matching_file = sig_dict[matching_hash]
            tqdm.write(f"The file matches virus name: {matching_file}.")
            matches.append(matching_file)

    if matches:
        tqdm.write(f"The matches are: {matches}")
    else:
        tqdm.write("No viruses were found.")

    tqdm.write(f"The number of files scanned were {len(files_to_hash)}.")
    tqdm.write(f"The number of virus signatures in the database is {len(sig_dict)}.")


def main() -> None:
    """Main function to parse command-line arguments and execute the malware scanner."""
    parser = argparse.ArgumentParser(description="Malware Scanner using ClamAV dataset.")
    parser.add_argument("--fetch-dataset", action="store_true", help="Fetch the ClamAV dataset and extract it.")
    parser.add_argument("--search-dirs", nargs="+", help="Specify the directory to scan for viruses.")
    parser.add_argument("--max-file-size", type=int, help="Skip files larger than the specified size (in MB).")
    parser.add_argument("--exclude-dirs", nargs="+", help="Specify directories to exclude from scanning.")
    parser.add_argument("--verbose", action="store_true", help="Log each file scanned")
    args = parser.parse_args()

    if args.fetch_dataset:
        download_dataset()
        extract_dataset()
        cleanup_files()
    else:
        if not os.path.exists(EXTRACTED_FILE):
            tqdm.write("Error: ClamAV dataset not found. Please fetch or extract the dataset.")
            sys.exit(1)

        if args.search_dirs and len(args.search_dirs) > 0:
            search_dirs = [normpath(directory) for directory in args.search_dirs]
            for directory in search_dirs:
                if not os.path.exists(directory):
                    tqdm.write(f"Error: Specified directory '{directory}' does not exist.")
                    sys.exit(1)
        else:
            tqdm.write("Scanning the current directory since no `--search-dirs` was provided")
            search_dirs = [os.getcwd()]

        signatures = load_signatures()
        scan_files(search_dirs, signatures, args.max_file_size, args.exclude_dirs, args.verbose)


if __name__ == "__main__":
    main()
